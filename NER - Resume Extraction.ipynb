{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NER - YAML.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QxJifO0TJWS"
      },
      "source": [
        "<h1><center>NER - Resume Extractor</center></h1>\n",
        "<h1><center>By: Team ZeRoS</center></h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmQ-MuJ0TpMy"
      },
      "source": [
        "## Problem Description:\n",
        "When companies recruit for any position, they usually end up receiving thousands, if not millions, of resumes. Such a uge number of resumes makes the task of going over all these resumes an extremely difficult and tedious job for HR employees. This made a lot of companies opt for systems that take the necessary information from the candidate after they fill an application with all the required fields. The solution worked greatly for employers; nevertheless, candidates have always found it very illogical to spend tens of hours sharpening their CVs and cover letters only to find out that they must spend another hour or so re-entering all the information they have on their CVs in the designated fields."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZBskvCJUGGb"
      },
      "source": [
        "## Business Understanding:\n",
        "It is often observed by HR that the manual process of evaluation of Resumes in bulk which are populated with excess information often becomes tedious and hectic. Therefore, we could automate this process by reading several formats of files (CV). Then using some basic techniques of Natural Language Processing like word parsing, chunking, regex parser and/or Named Entity Recognition to easily capture information like name, email id, address, educational qualification, experience in seconds from a large number of documents."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYHGjof6SE-f"
      },
      "source": [
        "## File Ingestion and Schema Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "buEuUaqaFer8",
        "outputId": "59961cb1-bfc2-4bfa-afa7-28df9edb1669"
      },
      "source": [
        "%%writefile testutility.py\n",
        "import logging\n",
        "import os\n",
        "import subprocess\n",
        "import yaml\n",
        "import pandas as pd\n",
        "import datetime \n",
        "import gc\n",
        "import re\n",
        "\n",
        "def read_yml_file(file_path):\n",
        "    with open(file_path, 'r') as stream:\n",
        "        try:\n",
        "            return yaml.safe_load(stream)\n",
        "        except yaml.YAMLError as exc:\n",
        "            logging.error(exc)\n",
        "\n",
        "def replacer(string, char):\n",
        "    pattern = char + '{2,}'\n",
        "    string = re.sub(pattern, char, string)\n",
        "    return string\n",
        "\n",
        "def col_validate(df, col_config):\n",
        "  cols = df.columns\n",
        "  cols = cols.str.strip()\n",
        "  cols.str.replace(\"_\", \"\")\n",
        "  cols = list(map(lambda x: replacer(x, ' '), list(cols)))\n",
        "  expected_col = list(map(lambda x: x.lower(),  col_config['columns']))\n",
        "  cols.sort()\n",
        "  expected_col.sort()\n",
        "  if len(cols) == len(expected_col) and cols == expected_col:\n",
        "    print(\"Column name and Column length Validation Passed!!\")\n",
        "    return 1\n",
        "  else:\n",
        "    print(\"Column name and Column length Validation Failed..\")\n",
        "    mismatched_columns_file = list(set(cols).difference(expected_col))\n",
        "    print(\"Following File columns are not in the YAML file\", mismatched_columns_file)\n",
        "    missing_YAML_file = list(set(expected_col).difference(cols))\n",
        "    print(\"Following YAML columns are not in the file uploaded\", missing_YAML_file)\n",
        "    logging.info(f'df columns: {cols}')\n",
        "    logging.info(f'expected columns: {expected_col}')\n",
        "    return 0\n",
        "\n",
        "# Function to get the size of dataset\n",
        "def humanbytes(B):\n",
        "  'Return the given bytes as a human friendly KB, MB, GB, or TB string'\n",
        "  B = float(B)\n",
        "  KB = float(1024)\n",
        "  MB = float(KB ** 2) # 1,048,576\n",
        "  GB = float(KB ** 3) # 1,073,741,824\n",
        "  TB = float(KB ** 4) # 1,099,511,627,776\n",
        "\n",
        "  if B < KB:\n",
        "    return '{0} {1}'.format(B,'Bytes' if 0 == B > 1 else 'Byte')\n",
        "  elif KB <= B < MB:\n",
        "    return '{0:.2f} KB'.format(B/KB)\n",
        "  elif MB <= B < GB:\n",
        "    return '{0:.2f} MB'.format(B/MB)\n",
        "  elif GB <= B < TB:\n",
        "    return '{0:.2f} GB'.format(B/GB)\n",
        "  elif TB <= B:\n",
        "    return '{0:.2f} TB'.format(B/TB)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting testutility.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tqguN9yMKSr"
      },
      "source": [
        "# Writing YAML File"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmyoaspcMLtX",
        "outputId": "b82535da-acaa-4e0c-d817-bbfa63f4f5a3"
      },
      "source": [
        "%%writefile file.yaml\n",
        "columns: \n",
        "  - annotation\n",
        "  - content\n",
        "dataset_name: resumes\n",
        "dtypes: \n",
        "  annotation: list\n",
        "  content: str\n",
        "file_name: Resume\n",
        "file_type: json\n",
        "skip_leading_rows: 1\n",
        "table_name: resumes"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting file.yaml\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajGscViHSPPK"
      },
      "source": [
        "# Reading the Configuration File"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSVL75ECNXwH"
      },
      "source": [
        "# Read config file\n",
        "import testutility as util\n",
        "col_config = util.read_yml_file(\"file.yaml\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpbPs4jyNmlE",
        "outputId": "51f1698c-99ce-49cc-f37d-c6e9abeb201e"
      },
      "source": [
        "#inspecting data of config file\n",
        "col_config"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'columns': ['annotation', 'content'],\n",
              " 'dataset_name': 'resumes',\n",
              " 'dtypes': {'annotation': 'list', 'content': 'str'},\n",
              " 'file_name': 'Resume',\n",
              " 'file_type': 'json',\n",
              " 'skip_leading_rows': 1,\n",
              " 'table_name': 'resumes'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "K0tl4KmwPjfK",
        "outputId": "89e4b13a-bdef-4dbc-9d53-dcd00cd500f9"
      },
      "source": [
        "# Read the file using yaml config file\n",
        "file_type = col_config['file_type']\n",
        "source_file = col_config['file_name'] + f'.{file_type}'\n",
        "source_file"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Resume.json'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "ROiMEHPINmda",
        "outputId": "c796f469-72e4-4d03-8e9b-bc0788698d73"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_json(source_file, lines=True)\n",
        "df.to_csv('dataframe.csv', index = None)\n",
        "df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>annotation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Govardhana K\\nSenior Software Engineer\\n\\nBeng...</td>\n",
              "      <td>[{'label': ['Companies worked at'], 'points': ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Harini Komaravelli\\nTest Analyst at Oracle, Hy...</td>\n",
              "      <td>[{'label': ['Companies worked at'], 'points': ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Hartej Kathuria\\nData Analyst Intern - Oracle ...</td>\n",
              "      <td>[{'label': ['Skills'], 'points': [{'start': 22...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Ijas Nizamuddin\\nAssociate Consultant - State ...</td>\n",
              "      <td>[{'label': ['Skills'], 'points': [{'start': 46...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Imgeeyaul Ansari\\njava developer\\n\\nPune, Maha...</td>\n",
              "      <td>[{'label': ['Skills'], 'points': [{'start': 18...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             content                                         annotation\n",
              "0  Govardhana K\\nSenior Software Engineer\\n\\nBeng...  [{'label': ['Companies worked at'], 'points': ...\n",
              "1  Harini Komaravelli\\nTest Analyst at Oracle, Hy...  [{'label': ['Companies worked at'], 'points': ...\n",
              "2  Hartej Kathuria\\nData Analyst Intern - Oracle ...  [{'label': ['Skills'], 'points': [{'start': 22...\n",
              "3  Ijas Nizamuddin\\nAssociate Consultant - State ...  [{'label': ['Skills'], 'points': [{'start': 46...\n",
              "4  Imgeeyaul Ansari\\njava developer\\n\\nPune, Maha...  [{'label': ['Skills'], 'points': [{'start': 18..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BxbnNSJNmWe",
        "outputId": "9acb3aed-c27d-4052-b914-342c7c371dfd"
      },
      "source": [
        "# Getting the size of the dataset\n",
        "size = df.memory_usage(deep=True).sum()\n",
        "file_size = util.humanbytes(size)\n",
        "print(file_size)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.41 MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBZaBFNnAc9k",
        "outputId": "11ebb2b3-6ed6-44e1-eedf-fa4ed144d6f7"
      },
      "source": [
        "# Checking the shape of dataframe\n",
        "df.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JdQQcwasAc0Y",
        "outputId": "1eb047c0-82a2-4936-8bb4-731297435369"
      },
      "source": [
        "# Checking no. of NA Values\n",
        "df.isnull().sum()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "content       0\n",
              "annotation    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIMeMq75_7YU",
        "outputId": "e8fba35d-c31d-4520-9fa0-d04e23bf42d3"
      },
      "source": [
        "df['annotation'][0]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': ['Companies worked at'],\n",
              "  'points': [{'end': 1754, 'start': 1749, 'text': 'Oracle'}]},\n",
              " {'label': ['Companies worked at'],\n",
              "  'points': [{'end': 1701, 'start': 1696, 'text': 'Oracle'}]},\n",
              " {'label': ['Companies worked at'],\n",
              "  'points': [{'end': 1422, 'start': 1417, 'text': 'Oracle'}]},\n",
              " {'label': ['Skills'],\n",
              "  'points': [{'end': 1792,\n",
              "    'start': 1356,\n",
              "    'text': 'Languages: Core Java, Go Lang, Data Structures & Algorithms, Oracle\\nPL-SQL programming, Sales Force with APEX.\\nTools: RADTool, Jdeveloper, NetBeans, Eclipse, SQL developer,\\nPL/SQL Developer, WinSCP, Putty\\nWeb Technologies: JavaScript, XML, HTML, Webservice\\n\\nOperating Systems: Linux, Windows\\nVersion control system SVN & Git-Hub\\nDatabases: Oracle\\nMiddleware: Web logic, OC4J\\nProduct FLEXCUBE: Oracle FLEXCUBE Versions 10.x, 11.x and 12.x'}]},\n",
              " {'label': ['Companies worked at'],\n",
              "  'points': [{'end': 1214, 'start': 1209, 'text': 'Oracle'}]},\n",
              " {'label': ['Skills'],\n",
              "  'points': [{'end': 1247,\n",
              "    'start': 1136,\n",
              "    'text': 'APEX. (Less than 1 year), Data Structures (3 years), FLEXCUBE (5 years), Oracle (5 years),\\nAlgorithms (3 years)\\n'}]},\n",
              " {'label': ['Graduation Year'],\n",
              "  'points': [{'end': 931, 'start': 928, 'text': '2012'}]},\n",
              " {'label': ['College Name'],\n",
              "  'points': [{'end': 888,\n",
              "    'start': 858,\n",
              "    'text': 'Adithya Institute of Technology'}]},\n",
              " {'label': ['Degree'],\n",
              "  'points': [{'end': 855,\n",
              "    'start': 821,\n",
              "    'text': 'B.E in Computer Science Engineering'}]},\n",
              " {'label': ['Graduation Year'],\n",
              "  'points': [{'end': 790, 'start': 787, 'text': '2012'}]},\n",
              " {'label': ['Companies worked at'],\n",
              "  'points': [{'end': 749, 'start': 744, 'text': 'Oracle'}]},\n",
              " {'label': ['Designation'],\n",
              "  'points': [{'end': 741, 'start': 722, 'text': 'Associate Consultant'}]},\n",
              " {'label': ['Companies worked at'],\n",
              "  'points': [{'end': 663, 'start': 658, 'text': 'Oracle'}]},\n",
              " {'label': ['Designation'],\n",
              "  'points': [{'end': 655, 'start': 640, 'text': 'Staff Consultant'}]},\n",
              " {'label': ['Companies worked at'],\n",
              "  'points': [{'end': 579, 'start': 574, 'text': 'Oracle'}]},\n",
              " {'label': ['Designation'],\n",
              "  'points': [{'end': 572, 'start': 555, 'text': 'Senior Consultant\\n'}]},\n",
              " {'label': ['Companies worked at'],\n",
              "  'points': [{'end': 492, 'start': 470, 'text': 'Cloud Lending Solutions'}]},\n",
              " {'label': ['Designation'],\n",
              "  'points': [{'end': 468,\n",
              "    'start': 444,\n",
              "    'text': 'Senior Software Engineer\\n'}]},\n",
              " {'label': ['Companies worked at'],\n",
              "  'points': [{'end': 313, 'start': 308, 'text': 'Oracle'}]},\n",
              " {'label': ['Companies worked at'],\n",
              "  'points': [{'end': 239, 'start': 234, 'text': 'Oracle'}]},\n",
              " {'label': ['Companies worked at'],\n",
              "  'points': [{'end': 197, 'start': 175, 'text': 'Cloud Lending Solutions'}]},\n",
              " {'label': ['Email Address'],\n",
              "  'points': [{'end': 136,\n",
              "    'start': 93,\n",
              "    'text': 'indeed.com/r/Govardhana-K/\\nb2de315d95905b68\\n'}]},\n",
              " {'label': ['Location'],\n",
              "  'points': [{'end': 47, 'start': 39, 'text': 'Bengaluru'}]},\n",
              " {'label': ['Designation'],\n",
              "  'points': [{'end': 37, 'start': 13, 'text': 'Senior Software Engineer\\n'}]},\n",
              " {'label': ['Name'],\n",
              "  'points': [{'end': 11, 'start': 0, 'text': 'Govardhana K'}]}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "id": "Kt6CZZlU_7YV",
        "outputId": "472aef1f-b6c5-4c1c-ad03-0fc6c9b7882f"
      },
      "source": [
        "df['content'][0]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Govardhana K\\nSenior Software Engineer\\n\\nBengaluru, Karnataka, Karnataka - Email me on Indeed: indeed.com/r/Govardhana-K/\\nb2de315d95905b68\\n\\nTotal IT experience 5 Years 6 Months\\nCloud Lending Solutions INC 4 Month • Salesforce Developer\\nOracle 5 Years 2 Month • Core Java Developer\\nLanguages Core Java, Go Lang\\nOracle PL-SQL programming,\\nSales Force Developer with APEX.\\n\\nDesignations & Promotions\\n\\nWilling to relocate: Anywhere\\n\\nWORK EXPERIENCE\\n\\nSenior Software Engineer\\n\\nCloud Lending Solutions -  Bangalore, Karnataka -\\n\\nJanuary 2018 to Present\\n\\nPresent\\n\\nSenior Consultant\\n\\nOracle -  Bangalore, Karnataka -\\n\\nNovember 2016 to December 2017\\n\\nStaff Consultant\\n\\nOracle -  Bangalore, Karnataka -\\n\\nJanuary 2014 to October 2016\\n\\nAssociate Consultant\\n\\nOracle -  Bangalore, Karnataka -\\n\\nNovember 2012 to December 2013\\n\\nEDUCATION\\n\\nB.E in Computer Science Engineering\\n\\nAdithya Institute of Technology -  Tamil Nadu\\n\\nSeptember 2008 to June 2012\\n\\nhttps://www.indeed.com/r/Govardhana-K/b2de315d95905b68?isid=rex-download&ikw=download-top&co=IN\\nhttps://www.indeed.com/r/Govardhana-K/b2de315d95905b68?isid=rex-download&ikw=download-top&co=IN\\n\\n\\nSKILLS\\n\\nAPEX. (Less than 1 year), Data Structures (3 years), FLEXCUBE (5 years), Oracle (5 years),\\nAlgorithms (3 years)\\n\\nLINKS\\n\\nhttps://www.linkedin.com/in/govardhana-k-61024944/\\n\\nADDITIONAL INFORMATION\\n\\nTechnical Proficiency:\\n\\nLanguages: Core Java, Go Lang, Data Structures & Algorithms, Oracle\\nPL-SQL programming, Sales Force with APEX.\\nTools: RADTool, Jdeveloper, NetBeans, Eclipse, SQL developer,\\nPL/SQL Developer, WinSCP, Putty\\nWeb Technologies: JavaScript, XML, HTML, Webservice\\n\\nOperating Systems: Linux, Windows\\nVersion control system SVN & Git-Hub\\nDatabases: Oracle\\nMiddleware: Web logic, OC4J\\nProduct FLEXCUBE: Oracle FLEXCUBE Versions 10.x, 11.x and 12.x\\n\\nhttps://www.linkedin.com/in/govardhana-k-61024944/'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_HpqTrNVCvS",
        "outputId": "81154ea5-825d-41e9-f7fd-5fbe7150ec54"
      },
      "source": [
        "# Validating Input File\n",
        "if util.col_validate(df, col_config) == 0:\n",
        "    print(\"Validation Failed!!\")\n",
        "else:\n",
        "    print(\"Column Validation Passed..\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Column name and Column length Validation Passed!!\n",
            "Column Validation Passed..\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4GkCr9gYAgZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}